{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Part A: Autoencoder Neural Networks\n",
        "\n"
      ],
      "metadata": {
        "id": "tOF4cXxNlDfM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "PaSpfg8s_ZIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from utils import *\n",
        "\n",
        "from scipy.sparse import load_npz\n",
        "import csv\n",
        "import os"
      ],
      "metadata": {
        "id": "hLW-MkuOlyIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Autoencoder"
      ],
      "metadata": {
        "id": "yhuiLm48xGZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AutoEncoder(nn.Module):\n",
        "    torch.manual_seed(42)\n",
        "    def __init__(self, num_question, k=100):\n",
        "        \"\"\" Initialize a class AutoEncoder.\n",
        "\n",
        "        :param num_question: int\n",
        "        :param k: int\n",
        "        \"\"\"\n",
        "        super(AutoEncoder, self).__init__()\n",
        "\n",
        "        # Define linear functions.\n",
        "        self.encoder = nn.Linear(num_question, k) #self.g\n",
        "        self.decoder = nn.Linear(k, num_question) #self.h\n",
        "\n",
        "    def get_weight_norm(self):\n",
        "        \"\"\" Return ||W^1||^2 + ||W^2||^2.\n",
        "\n",
        "        :return: float\n",
        "        \"\"\"\n",
        "        g_w_norm = torch.norm(self.encoder.weight, 2) ** 2\n",
        "        h_w_norm = torch.norm(self.decoder.weight, 2) ** 2\n",
        "\n",
        "        return g_w_norm + h_w_norm\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\" Return a forward pass given inputs.\n",
        "\n",
        "        :param inputs: user vector.\n",
        "        :return: user vector.\n",
        "        \"\"\"\n",
        "\n",
        "        x = torch.sigmoid(self.encoder(inputs))\n",
        "        out = torch.sigmoid(self.decoder(x))\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "B3Q7gfhYmT6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy Evaluation Function"
      ],
      "metadata": {
        "id": "Pw3r3HQCxgAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, train_data, valid_data):\n",
        "    \"\"\" Evaluate the valid_data on the current model.\n",
        "\n",
        "    :param model: Module\n",
        "    :param train_data: 2D FloatTensor\n",
        "    :param valid_data: A dictionary {user_id: list,\n",
        "    question_id: list, is_correct: list}\n",
        "    :return: float\n",
        "    \"\"\"\n",
        "    # Tell PyTorch you are evaluating the model.\n",
        "    model.eval()\n",
        "\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    for i, u in enumerate(valid_data[\"user_id\"]):\n",
        "        inputs = Variable(train_data[u]).unsqueeze(0)\n",
        "        output = model(inputs)\n",
        "\n",
        "        guess = output[0][valid_data[\"question_id\"][i]].item() >= 0.5\n",
        "        if guess == valid_data[\"is_correct\"][i]:\n",
        "            correct += 1\n",
        "        total += 1\n",
        "    return correct / float(total)"
      ],
      "metadata": {
        "id": "_eBvYo-jlqVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Function"
      ],
      "metadata": {
        "id": "b8Y2HSeWxsl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, lr, lamb, train_matrix, zero_train_data, train_data, valid_data, num_epoch):\n",
        "    \"\"\" Train the neural network, where the objective also includes\n",
        "    a regularizer.\n",
        "\n",
        "    :param model: Module\n",
        "    :param lr: float\n",
        "    :param lamb: float\n",
        "    :param train_data: 2D FloatTensor\n",
        "    :param zero_train_data: 2D FloatTensor\n",
        "    :param train_data: Dict\n",
        "    :param valid_data: Dict\n",
        "    :param num_epoch: int\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "\n",
        "    # Tell PyTorch you are training the model.\n",
        "    model.train()\n",
        "\n",
        "    # Define optimizers and loss function.\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "    num_student = train_matrix.shape[0]\n",
        "    train_losses = []\n",
        "    train_accs = []\n",
        "    val_accs = []\n",
        "    eps = []\n",
        "\n",
        "    for epoch in range(0, num_epoch):\n",
        "        train_loss = 0.\n",
        "        eps.append(epoch)\n",
        "\n",
        "        for user_id in range(num_student):\n",
        "            inputs = Variable(zero_train_data[user_id]).unsqueeze(0)  #answers to all questions by a student\n",
        "            target = inputs.clone()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(inputs)\n",
        "\n",
        "            # Mask the target to only compute the gradient of valid entries.\n",
        "            nan_mask = np.isnan(train_matrix[user_id].unsqueeze(0).numpy())\n",
        "            target[0][nan_mask] = output[0][nan_mask]\n",
        "\n",
        "            loss = torch.sum((output - target) ** 2.)\n",
        "            loss.backward()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            optimizer.step()\n",
        "        train_acc = evaluate(model, zero_train_data, train_data)\n",
        "        valid_acc = evaluate(model, zero_train_data, valid_data)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        val_accs.append(valid_acc)\n",
        "        print(\"Epoch: {} \\tTraining Cost: {:.6f}\\t \"\n",
        "              \"Valid Acc: {}\".format(epoch, train_loss, valid_acc))\n",
        "\n",
        "      #plotting\n",
        "    plt.title(\"Training Loss vs. Epochs\")\n",
        "    plt.plot(eps, train_losses, label=\"Training Curve\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Training Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Accuracy vs. Epochs\")\n",
        "    plt.plot(eps, train_accs, label=\"Training Curve\")\n",
        "    plt.plot(eps, val_accs, label=\"Validation Curve\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "KyNcCf5UmYm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main Function"
      ],
      "metadata": {
        "id": "BoWlgVa3xwzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  zero_train_matrix, train_matrix, train_data, valid_data, test_data = load_data()\n",
        "\n",
        "  # Set model hyperparameters.\n",
        "  k = 50\n",
        "  num_questions = zero_train_matrix.shape[1]\n",
        "  model = AutoEncoder(num_question = num_questions, k = k)\n",
        "\n",
        "  # Set optimization hyperparameters.\n",
        "  lr = 0.01\n",
        "  num_epoch = 40\n",
        "  lamb = 0\n",
        "\n",
        "  train(model, lr, lamb, train_matrix, zero_train_matrix, train_data,\n",
        "          valid_data, num_epoch)"
      ],
      "metadata": {
        "id": "IRcc6tgsIyKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part B: Regularized Autoencoder Neural Networks"
      ],
      "metadata": {
        "id": "Kcw3_3uyx0h_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Function"
      ],
      "metadata": {
        "id": "d2WAyg9hyHgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_reg(model, lr, lamb, train_matrix, zero_train_data, train_data, valid_data, num_epoch):\n",
        "    \"\"\" Train the neural network, where the objective also includes\n",
        "    a regularizer.\n",
        "\n",
        "    :param model: Module\n",
        "    :param lr: float\n",
        "    :param lamb: float\n",
        "    :param train_data: 2D FloatTensor\n",
        "    :param zero_train_data: 2D FloatTensor\n",
        "    :param valid_data: Dict\n",
        "    :param num_epoch: int\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "\n",
        "    norm = model.get_weight_norm()\n",
        "    norm = norm.detach().numpy()\n",
        "    print(\"norm = \", norm)\n",
        "\n",
        "    # Tell PyTorch you are training the model.\n",
        "    model.train()\n",
        "\n",
        "    # Define optimizers and loss function.\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "    num_student = train_matrix.shape[0]\n",
        "\n",
        "    eps = []\n",
        "    train_losses = []\n",
        "    train_accs = []\n",
        "    val_accs = []\n",
        "\n",
        "    for epoch in range(0, num_epoch):\n",
        "        train_loss = 0.\n",
        "\n",
        "        for user_id in range(num_student):\n",
        "            inputs = Variable(zero_train_data[user_id]).unsqueeze(0)  #answers to all questions by a student\n",
        "            target = inputs.clone()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(inputs)\n",
        "\n",
        "            # Mask the target to only compute the gradient of valid entries.\n",
        "            nan_mask = np.isnan(train_matrix[user_id].unsqueeze(0).numpy())\n",
        "            target[0][nan_mask] = output[0][nan_mask]\n",
        "\n",
        "            loss = torch.sum(((output - target) ** 2.)) + lamb*norm/2\n",
        "            loss.backward()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            optimizer.step()\n",
        "\n",
        "        train_acc = evaluate(model, zero_train_data, train_data)\n",
        "        valid_acc = evaluate(model, zero_train_data, valid_data)\n",
        "\n",
        "        eps.append(epoch)\n",
        "        train_losses.append(train_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        val_accs.append(valid_acc)\n",
        "        print(\"Epoch: {} \\tTraining Cost: {:.6f}\\t \"\n",
        "              \"Valid Acc: {}\".format(epoch, train_loss, valid_acc))\n",
        "\n",
        "      #plotting\n",
        "    plt.title(\"Training Loss vs. Epochs\")\n",
        "    plt.plot(eps, train_losses, label=\"Training Curve\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Training Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Accuracy vs. Epochs\")\n",
        "    plt.plot(eps, train_accs, label=\"Training Curve\")\n",
        "    plt.plot(eps, val_accs, label=\"Validation Curve\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "RxfkmVIB4KKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  zero_train_matrix, train_matrix, train_data, valid_data, test_data = load_data()\n",
        "\n",
        "  k = 50\n",
        "  num_questions = zero_train_matrix.shape[1]\n",
        "  model_reg = AutoEncoder(num_question = num_questions, k = k)\n",
        "\n",
        "  # Set optimization hyperparameters.\n",
        "  lr = 0.01\n",
        "  num_epoch = 40\n",
        "  lamb = 0.001\n",
        "\n",
        "  train_reg(model_reg, lr, lamb, train_matrix, zero_train_matrix, train_data, valid_data, num_epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJnaCIu14gCm",
        "outputId": "397a78dd-6e14-471f-ec83-d54269969b84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "norm =  596.55023\n",
            "Epoch: 0 \tTraining Cost: 13674.634931\t Valid Acc: 0.622495060683037\n",
            "Epoch: 1 \tTraining Cost: 12463.829630\t Valid Acc: 0.6363251481795089\n",
            "Epoch: 2 \tTraining Cost: 11755.400912\t Valid Acc: 0.6515664690939882\n",
            "Epoch: 3 \tTraining Cost: 11162.529329\t Valid Acc: 0.6642675698560542\n",
            "Epoch: 4 \tTraining Cost: 10671.385089\t Valid Acc: 0.6699125035280835\n",
            "Epoch: 5 \tTraining Cost: 10273.309865\t Valid Acc: 0.6758396838837144\n",
            "Epoch: 6 \tTraining Cost: 9935.320303\t Valid Acc: 0.6804967541631386\n",
            "Epoch: 7 \tTraining Cost: 9642.127272\t Valid Acc: 0.6819079875811459\n",
            "Epoch: 8 \tTraining Cost: 9389.196759\t Valid Acc: 0.6809201241885408\n",
            "Epoch: 9 \tTraining Cost: 9156.072784\t Valid Acc: 0.6812023708721423\n",
            "Epoch: 10 \tTraining Cost: 8945.150385\t Valid Acc: 0.6799322607959356\n",
            "Epoch: 11 \tTraining Cost: 8771.104641\t Valid Acc: 0.6797911374541349\n",
            "Epoch: 12 \tTraining Cost: 8592.795979\t Valid Acc: 0.678662150719729\n",
            "Epoch: 13 \tTraining Cost: 8432.629589\t Valid Acc: 0.6775331639853232\n",
            "Epoch: 14 \tTraining Cost: 8285.458994\t Valid Acc: 0.6779565340107254\n",
            "Epoch: 15 \tTraining Cost: 8143.978165\t Valid Acc: 0.6785210273779283\n",
            "Epoch: 16 \tTraining Cost: 8018.601536\t Valid Acc: 0.6752751905165114\n",
            "Epoch: 17 \tTraining Cost: 7898.772879\t Valid Acc: 0.6734405870731018\n",
            "Epoch: 18 \tTraining Cost: 7779.305832\t Valid Acc: 0.6730172170476997\n",
            "Epoch: 19 \tTraining Cost: 7684.152042\t Valid Acc: 0.6727349703640982\n",
            "test accuracy =  0.5094552639006492\n"
          ]
        }
      ]
    }
  ]
}